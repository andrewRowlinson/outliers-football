{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the fbref big-5 league data into a single dataframe. And standardise stats to per 90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through the scraped fbref data and where there is more than one record per player sum the stats (if relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [['fbref_playingtime-18.parquet', 'fbref_playingtime-19.parquet', 'fbref_playingtime-20.parquet'],\n",
    "         ['fbref_defence-18.parquet', 'fbref_defence-19.parquet', 'fbref_defence-20.parquet'],\n",
    "         ['fbref_gca-18.parquet', 'fbref_gca-19.parquet', 'fbref_gca-20.parquet'],\n",
    "         ['fbref_misc-18.parquet', 'fbref_misc-19.parquet', 'fbref_misc-20.parquet'],\n",
    "         ['fbref_passing-18.parquet', 'fbref_passing-19.parquet', 'fbref_passing-20.parquet'],\n",
    "         ['fbref_passing_types-18.parquet', 'fbref_passing_types-19.parquet', 'fbref_passing_types-20.parquet'],\n",
    "         ['fbref_possession-18.parquet', 'fbref_possession-19.parquet', 'fbref_possession-20.parquet'],\n",
    "         ['fbref_shooting-18.parquet', 'fbref_shooting-19.parquet', 'fbref_shooting-20.parquet'],\n",
    "         ['fbref_stats-18.parquet', 'fbref_stats-19.parquet', 'fbref_stats-20.parquet']]\n",
    "\n",
    "# dropping these columns as either impossible to re-create as averages and need to recreate from the summed stats\n",
    "drop_list = ['playing_time_min%', 'starts_mn/start', 'subs_mn/sub', 'team_success_(xg)_on-off',\n",
    "             'team_success_on-off', 'team_success_ppm', 'playing_time_mn/mp',\n",
    "             'standard_g/sh', 'standard_g/sot', 'expected_npxg/sh']\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "    dfs = [pd.read_parquet(os.path.join('data', 'fbref', f)) for f in file]\n",
    "    \n",
    "    # only keep 2018 and 2019 results if the player played in 2020-21\n",
    "    dfs[0] = dfs[0][dfs[0].player_link.isin(dfs[2].player_link)]\n",
    "    dfs[1] = dfs[1][dfs[1].player_link.isin(dfs[2].player_link)]\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    # split players into one club/ multi club\n",
    "    df_one_club = df.drop_duplicates('player_link', keep=False).copy()\n",
    "    df_multi_club = df[df.duplicated('player_link', keep=False)]\n",
    "    \n",
    "    # split columns into groups (per 90 stats/ percentage stats, stats that sum)\n",
    "    cols = (df.columns[8:-2])\n",
    "    cols90 = [c for c in cols if '90' in c and c != '90s']\n",
    "    colspct = [c for c in cols if '%' in c]\n",
    "    drop_list = drop_list + cols90 + colspct\n",
    "    cols_to_sum = [c for c in cols if c not in drop_list]\n",
    "    \n",
    "    # sum up the stats that sum. where a player has been at multiple clubs we are going to sum the stats over these clubs\n",
    "    df_multi_club_sum = df_multi_club.groupby('player_link')[cols_to_sum].sum().reset_index()\n",
    "    df_multi_club = (df_multi_club[['rk', 'player', 'nation', 'pos', 'squad', 'comp', 'age', 'born', \n",
    "                                    'player_link', 'match_link']].drop_duplicates('player_link', keep='last'))\n",
    "    df_multi_club = df_multi_club.merge(df_multi_club_sum, on='player_link', validate='1:1')\n",
    "    \n",
    "    # drop cols that don't sum\n",
    "    df_one_club.drop(drop_list, axis='columns', errors='ignore', inplace=True)\n",
    "    \n",
    "    # concatenate back with the players with only one club\n",
    "    df = pd.concat([df_one_club, df_multi_club])\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the dataframes in the list into one dataframe and drop some repeated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_list[0]\n",
    "for i, df_join in enumerate(df_list[1:]):\n",
    "    df = df.merge(df_join[df_join.columns[8:]], on='player_link', validate='1:1', suffixes=['', f'_{i}'])\n",
    "\n",
    "# drop some columns\n",
    "drop_cols = [c for c in df.columns if c[-1].isnumeric() and c[-2] == '_']\n",
    "df.drop(drop_cols, axis='columns', inplace=True)\n",
    "cols_repeated = ['att', 'outcomes_cmp',  'expected_xa', 'playing_time_starts', \n",
    "                 'performance_tklw', 'performance_ast', 'performance_int', 'performance_crs',\n",
    "                 'performance_pk', 'performance_pkatt', 'performance_gls', 'performance_pk', 'performance_pkatt']\n",
    "df.drop(cols_repeated, axis='columns', inplace=True)\n",
    "df.drop(['rk', 'standard_dist', 'age'], axis='columns', inplace=True)\n",
    "\n",
    "# reorder cols\n",
    "str_cols = [c for c in df.columns if (df[c].dtype == object) | (c == '90s')]\n",
    "other_cols = [c for c in df.columns if (df[c].dtype != object) & (c != '90s')]\n",
    "col_order = str_cols + other_cols\n",
    "df = df[col_order].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get average shot distance (can't just sum as it's already averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shots = pd.concat([pd.read_parquet(os.path.join('data', 'fbref', f))[['player_link',\n",
    "                                                                         'standard_dist', 'standard_sh']] for f in files[7]])\n",
    "df_shots.fillna(0, inplace=True)\n",
    "df_shots['distance'] = df_shots.standard_dist * df_shots.standard_sh\n",
    "df_shots = df_shots.groupby(['player_link'])[['standard_sh', 'distance']].sum().reset_index()\n",
    "df_shots['standard_dist'] = df_shots['distance'].divide(df_shots['standard_sh']).round(1).fillna(0)\n",
    "df_shots = df_shots[['player_link', 'standard_dist']].copy()\n",
    "df = df.merge(df_shots, how='left', on='player_link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the percent/ ratio columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vs_dribbles_tkl%'] = (df['vs_dribbles_tkl'].divide(df['vs_dribbles_att']) * 100.).round(1)\n",
    "df['pressures_%'] = (df['pressures_succ'].divide(df['pressures_press']) * 100.).round(1)\n",
    "df['aerial_duels_won%'] =  (df['aerial_duels_won'].divide(df['aerial_duels_won'] + df['aerial_duels_lost']) * 100.).round(1)\n",
    "df['total_cmp%'] =  (df['total_cmp'].divide(df['total_att']) * 100.).round(1)\n",
    "df['short_cmp%'] =  (df['short_cmp'].divide(df['short_att']) * 100.).round(1)\n",
    "df['medium_cmp%'] =  (df['medium_cmp'].divide(df['medium_att']) * 100.).round(1)\n",
    "df['long_cmp%'] =  (df['long_cmp'].divide(df['long_att']) * 100.).round(1)\n",
    "df['playing_time_mn/mp'] =  (df['playing_time_min'].divide(df['playing_time_mp'])).round(1)\n",
    "df['dribbles_succ%'] =  (df['dribbles_succ'].divide(df['dribbles_att']) * 100.).round(1)\n",
    "df['receiving_rec%'] =  (df['receiving_rec'].divide(df['receiving_targ']) * 100.).round(1)\n",
    "# goal ratio columns\n",
    "non_penalty_sh = df['standard_sh'] - df['standard_pkatt']\n",
    "non_penalty_goals = df['standard_gls'] - df['standard_pk']\n",
    "df['standard_g/sh'] =  non_penalty_goals.divide(non_penalty_sh).round(2)\n",
    "df['expected_npxg/sh'] =  df['expected_npxg'].divide(non_penalty_sh).round(2)\n",
    "df['standard_g/sot'] = non_penalty_goals.divide(df['standard_sot']).round(2)\n",
    "df['standard_sot%'] =  (df['standard_sot'].divide(non_penalty_sh) * 100.).round(1)\n",
    "# to be considered leader in fbref have to have more than .395 shots per game / made it so 10+ shots too\n",
    "mask_null_shot = (non_penalty_sh.divide(df.playing_time_mp) < .395) | (non_penalty_sh < 10)\n",
    "df.loc[mask_null_shot, ['standard_g/sh', 'expected_npxg/sh', 'standard_sot%']] = np.nan\n",
    "# to be considered leader in fbref have to have more than .111 sots on target per game / made it so 4+ shots too\n",
    "mask_null_sot = (df.standard_sot.divide(df.playing_time_mp) < .111) | (df.standard_sot < 4)\n",
    "df.loc[mask_null_sot, ['standard_g/sot']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise columns to per 90 stats if not ratio/ percent stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_standardise = list(df.columns[15:-15])\n",
    "df[cols_to_standardise] = (df[cols_to_standardise].divide(df.playing_time_min, axis='rows') * 90.).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(os.path.join('data', 'fbref_combined.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
