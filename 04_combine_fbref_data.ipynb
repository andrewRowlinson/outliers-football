{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the fbref data into a single dataframe. And standardise stats to per 90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We only keep players who have played in the in scope leagues in the final year (2024).\n",
    "- We keep one row per player and aggregate their stats over all the seasons in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('data', 'fbref_clean'), exist_ok=True)\n",
    "os.makedirs(os.path.join('data', 'fbref_clean', '2024'), exist_ok=True)\n",
    "os.makedirs(os.path.join('data', 'fbref_clean', '2023'), exist_ok=True)\n",
    "os.makedirs(os.path.join('data', 'fbref_clean', '2022'), exist_ok=True)\n",
    "os.makedirs(os.path.join('data', 'fbref_clean', 'all_years'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUES = glob.glob(os.path.join('data', 'fbref', '*'))\n",
    "LEAGUES = [f for f in LEAGUES if os.path.isdir(f)]\n",
    "FILES = ['keepersadv.parquet', 'gca.parquet', 'defense.parquet', 'playingtime.parquet',\n",
    "         'passing.parquet', 'passing_types.parquet', 'stats.parquet', 'shooting.parquet',\n",
    "         'keepers.parquet', 'misc.parquet', 'possession.parquet']\n",
    "YEARS = [2022, 2023, 2024]\n",
    "for year in YEARS:\n",
    "    for file in FILES:\n",
    "        all_leagues = []\n",
    "        for league in LEAGUES:\n",
    "            df = pd.read_parquet(os.path.join(league, str(year), file))\n",
    "            df['league'] = os.path.basename(league)\n",
    "            all_leagues.append(df)\n",
    "        df = pd.concat(all_leagues)\n",
    "        df.to_parquet(os.path.join('data', 'fbref_clean', str(year), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in YEARS:\n",
    "    clean_files = glob.glob(os.path.join('data', 'fbref_clean', str(year), '*'))\n",
    "    df = pd.read_parquet([f for f in clean_files if 'playingtime' in f][0])\n",
    "    clean_files = [f for f in clean_files if 'playingtime' not in f]\n",
    "    for f in clean_files:\n",
    "        df_temp = pd.read_parquet(f)\n",
    "        df = df.merge(df_temp, on=['player_link', 'squad', 'league'],\n",
    "                      how='left', suffixes=['', '_to_remove'])\n",
    "    cols_to_remove = [col for col in df.columns if '_to_remove' in col]\n",
    "    df.drop(cols_to_remove, axis='columns', inplace=True)\n",
    "    df.drop(['90s', 'att', 'expected_xag', 'penalty_kicks_pka',\n",
    "             'performance_ast', 'performance_crs', 'performance_ga',\n",
    "             'performance_gls', 'performance_int', 'performance_pk',\n",
    "             'performance_pkatt', 'performance_tklw',\n",
    "             'progression_prgc', 'progression_prgp',\n",
    "             'progression_prgr', 'starts_starts',\n",
    "            ], axis='columns', inplace=True)\n",
    "\n",
    "    # dropping these columns as either impossible to re-create as averages and need to recreate from the summed stats\n",
    "    drop_list = ['playing_time_min_percent', 'starts_mn_start', 'subs_mn_sub', 'team_success_xg_on_minus_off',\n",
    "                 'team_success_on_minus_off', 'team_success_ppm', 'playing_time_mn_mp',\n",
    "                 # these are ratios\n",
    "                 'standard_g_sh', 'standard_g_sot', 'expected_npxg_sh']\n",
    "    cols90 = [c for c in df.columns if '90' in c and c != 'playing_time_90s']\n",
    "    colspct = [c for c in df.columns if 'percent' in c]\n",
    "    df.drop(cols90 + colspct + drop_list, axis='columns', inplace=True)\n",
    "\n",
    "    df['year'] = year\n",
    "    df.to_parquet(os.path.join('data', 'fbref_clean', 'all_years', f'fbref_{year}.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean_files = glob.glob(os.path.join('data', 'fbref_clean', 'all_years', '*'))\n",
    "df = pd.read_parquet(all_clean_files)\n",
    "# add one column for shot total distance\n",
    "df['shot_total_distance'] = df['standard_dist'] * df['standard_sh']\n",
    "cols_to_sum = [c for c in df.columns if is_numeric_dtype(df[c]) and c not in ['age', 'born', 'year']]\n",
    "other_cols = [col for col in df.columns if col not in cols_to_sum]\n",
    "# split players into one club/ multi club\n",
    "df_one_club = df.drop_duplicates('player_link', keep=False).copy()\n",
    "df_multi_club = df[df.duplicated('player_link', keep=False)].sort_values(['year', 'playing_time_min']).copy()\n",
    "df_multi_club_sum = df_multi_club.groupby('player_link')[cols_to_sum].sum().reset_index()\n",
    "df_multi_club = df_multi_club[other_cols].drop_duplicates('player_link', keep='last').copy()\n",
    "df_multi_club = df_multi_club.merge(df_multi_club_sum, on='player_link', validate='1:1')\n",
    "df = pd.concat([df_one_club, df_multi_club])\n",
    "# recreate the average distance from the column for the shot total distance we created earlier\n",
    "df['standard_dist'] = df['shot_total_distance'].divide(df['standard_sh']).round(1).fillna(0)\n",
    "df.drop('shot_total_distance', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the percent/ ratio columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aerial_duels_won_percent'] =  (df['aerial_duels_won'].divide(df['aerial_duels_won'] + df['aerial_duels_lost']) * 100.).round(1)\n",
    "df['long_cmp_percent'] =  (df['long_cmp'].divide(df['long_att']) * 100.).round(1)\n",
    "df['medium_cmp_percent'] =  (df['medium_cmp'].divide(df['medium_att']) * 100.).round(1)\n",
    "df['short_cmp_percent'] =  (df['short_cmp'].divide(df['short_att']) * 100.).round(1)\n",
    "df['standard_sot_percent'] =  (df['standard_sot'].divide(df['standard_sh']) * 100.).round(1)\n",
    "df['total_cmp_percent'] =  (df['total_cmp'].divide(df['total_att']) * 100.).round(1)\n",
    "df['challenges_tkl_percent'] = (df['challenges_tkl'].divide(df['challenges_att']) * 100.).round(1)\n",
    "df['crosses_stp_percent'] = (df['crosses_stp'].divide(df['crosses_opp']) * 100.).round(1)\n",
    "df['launched_cmp_percent'] = (df['launched_cmp'].divide(df['launched_att']) * 100.).round(1)\n",
    "df['penalty_kicks_save_percent'] = (df['penalty_kicks_pksv'].divide(df['penalty_kicks_pkatt']) * 100.).round(1)\n",
    "df['performance_cs_percent'] = (df['performance_cs'].divide(df['playing_time_mp']) * 100.).round(1)\n",
    "df['take_ons_succ_percent'] = (df['take_ons_succ'].divide(df['take_ons_att']) * 100.).round(1)\n",
    "non_penalty_goals = df['standard_gls'] - df['standard_pk']\n",
    "df['standard_g/sh'] =  non_penalty_goals.divide(df['standard_sh']).round(2)\n",
    "df['expected_npxg/sh'] =  df['expected_npxg'].divide(df['standard_sh']).round(2)\n",
    "df['standard_g/sot'] = non_penalty_goals.divide(df['standard_sot']).round(2)\n",
    "df['standard_sot_percent'] =  (df['standard_sot'].divide(df['standard_sh']) * 100.).round(1)\n",
    "# to be considered leader in fbref have to have more than .395 shots per game / made it so 10+ shots too\n",
    "mask_null_shot = ((df['standard_sh'].divide(df['playing_time_mp']) < .395) |\n",
    "                  (df['standard_sh'] < 10))\n",
    "df.loc[mask_null_shot, ['standard_g/sh', 'expected_npxg/sh',\n",
    "                        'standard_sot_percent']] = np.nan\n",
    "# to be considered leader in fbref have to have more than .111 sots on target per game / made it so 4+ shots too\n",
    "mask_null_sot = ((df['standard_sot'].divide(df['playing_time_mp']) < .111) |\n",
    "                 (df['standard_sot'] < 4)\n",
    "                )\n",
    "df.loc[mask_null_sot, ['standard_g/sot']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise columns to per 90 stats if not ratio/ percent stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_per_90 = ['playing_time_mp', 'playing_time_min', 'playing_time_90s',\n",
    "                  'starts_compl', 'subs_subs', 'subs_unsub']\n",
    "for col in exclude_per_90:\n",
    "    cols_to_sum.remove(col)\n",
    "cols_to_sum.remove('shot_total_distance') # dropped already\n",
    "df[cols_to_sum] = (df[cols_to_sum].divide(df['playing_time_min'], axis='rows') * 90.).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(os.path.join('data', 'fbref_clean', 'fbref_combined.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
